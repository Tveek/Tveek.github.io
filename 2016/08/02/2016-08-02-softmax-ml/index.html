<!DOCTYPE html>
<html lang="">
  <head>
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="softmax分类器"/>







  <link rel="alternate" href="/default" title="Note">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.3.x" />



<link rel="canonical" href="http://yoursite.com/2016/08/02/2016-08-02-softmax-ml/"/>


<meta name="description" content="前段时间记录二分类问题，这几天一直在弄多分类的问题，这里介绍softmax这种多分类方法.$ $">
<meta name="keywords">
<meta property="og:type" content="article">
<meta property="og:title" content="softmax分类器">
<meta property="og:url" content="http://yoursite.com/2016/08/02/2016-08-02-softmax-ml/index.html">
<meta property="og:site_name" content="Note">
<meta property="og:description" content="前段时间记录二分类问题，这几天一直在弄多分类的问题，这里介绍softmax这种多分类方法.$ $">
<meta property="og:updated_time" content="2017-04-17T05:18:15.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="softmax分类器">
<meta name="twitter:description" content="前段时间记录二分类问题，这几天一直在弄多分类的问题，这里介绍softmax这种多分类方法.$ $">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.3.x" />







<script>
  var CONFIG = {
    search: false,
    searchPath: "/search.xml",
    fancybox: false,
    toc: true,
  }
</script>




  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?8466adbc25665cf7ee1a15e4fcb73643";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  <script type="text/javascript">
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-74273646-1', 'auto');
        ga('send', 'pageview');
  </script>



    <title> softmax分类器 · Note </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="mobile-header-logo">
    <a href="/." class="logo">Note</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            Home
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            Archives
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            Categories
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Note</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              Home
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              Archives
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              Categories
            
          </a>
        </li>
      
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          softmax分类器
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          Aug 2, 2016
        </span>
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">Contents</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#理论"><span class="toc-text">理论</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#代码"><span class="toc-text">代码</span></a></li></ol>
    </div>
  </div>


    <div class="post-content">
      
        <p>前段时间记录二分类问题，这几天一直在弄多分类的问题，这里介绍softmax这种多分类方法.$ $ <a id="more"></a></p>
<h1 id="理论">理论</h1>
<p>先大概的说一下它的分类原理，我们都知道机器学习<strong>无非就是学到一个函数</strong>，softmax的函数比较特殊，这个函数的一个输入对应多个该类输出，就是对于每个分类都有一个概率，最后选择概率大的分类作为最终的输出．下面还是来说公式<br> <strong>假设函数</strong><span class="math">\(h_{\theta}(x)\)</span>:<br></p>
<p><span class="math">\[
h_{\theta}(x^{(i)})=\begin{bmatrix}
p(y^{(i)}=1|x^{(i)};\theta)\\
p(y^{(i)}=2|x^{(i)};\theta)\\
\vdots \\
p(y^{(i)}=k|x^{(i)};\theta)
\end{bmatrix}=\frac{1}{\sum_{j=1}^{k}e^{\theta_{j}^{T}x^{(i)}}}\begin{bmatrix}
e^{\theta_{1}^{T}x^{(i)}}\\
e^{\theta_{2}^{T}x^{(i)}}\\
\vdots \\
e^{\theta_{k}^{T}x^{(i)}}
\end{bmatrix}
\]</span></p>
<p>至于为什么会选择这个假设函数，有兴趣的可以参考Andrew Ng的机器学习课程，主要是因为GLM，那里有严格的证明，这里就不列出来<br> 上面公式的<span class="math">\(\theta\)</span>这里还是说一下，它的形式为:<br></p>
<p><span class="math">\[
\begin{bmatrix}
\theta_{11} &amp;\theta_{12}  &amp;\cdots   &amp;\theta_{1k} \\
 \theta_{21}&amp;\theta_{22}  &amp;\cdots  &amp;\theta_{2k} \\
\vdots &amp; \vdots &amp; \vdots &amp;\vdots \\
 \theta_{f1}&amp;\theta_{f2}  &amp;\cdots  &amp;\theta_{fk}
\end{bmatrix}
\]</span></p>
<p><strong>其实就是每一列代表一个类别，f行表示每一类别都是有f个特征构成.</strong><br> 接下来就是<strong>损失函数</strong>出场了,还是利用最大似然的原理，具体的证明就不写了．</p>
<p><span class="math">\[
J(\theta)=-\frac{1}{m}[\sum_{i=1}^{m}\sum_{j=1}^{k}1\begin{Bmatrix}
y^{(i)}=j
\end{Bmatrix}log\frac{e^{\theta_{j}^{T}x^{(i)}}}{\sum_{j=1}^{k}e^{\theta_{j}^{T}x^{(i)}}}]+\frac{\lambda }{2}\sum_{i=1}^{m}\sum_{j=1}^{k}\theta_{ij}^{2}
\]</span></p>
<p>最后就是重要的<strong>偏导数</strong>：</p>
<p><span class="math">\[
\triangledown _{\theta_{j}}J({\theta})=-\frac{1}{m}\begin{bmatrix}
x^{(i)}(1\begin{Bmatrix}
y^{(i)}=j
\end{Bmatrix}-p(y^{(i)}=j|x^{(i)};\theta))
\end{bmatrix}+\lambda \theta
\]</span></p>
<p>如果完全的理解上面的公式，那么softmax的核心代码就可以写出来了，不过要想很好的理解这些公式，还是需要自己认真推导和理解的，这里只不过提供一个参考．</p>
<h1 id="代码">代码</h1>
<p>下面是mnist手写体的softmax分类的小例子,就是有很多写有0~9数字的图像，如何通过这些图像信息学到一个方程，最后用这个方程去识别其他0~9的图像，看能否成功</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># encoding=utf8</span></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> scipy.sparse</div><div class="line"><span class="keyword">import</span> scipy.optimize</div><div class="line"><span class="keyword">import</span> struct</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SoftMax</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="string">"""docstring for """</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_feature, num_class, lamda)</span>:</span></div><div class="line">        <span class="string">"""构成函数</span></div><div class="line">        Args:</div><div class="line">            num_feature:int类型;表示每张图片特征点的个数</div><div class="line">            num_class:int类型;表示总共有多少类别</div><div class="line">            lamda:float类型;衰减因子</div><div class="line">        """</div><div class="line">        self.num_feature=num_feature</div><div class="line">        self.num_class=num_class</div><div class="line">        self.lamda=lamda</div><div class="line">        <span class="comment"># 初始化theta</span></div><div class="line">        self.theta=np.zeros((num_feature,num_class))</div><div class="line">        <span class="comment"># self.theta=np.ones((num_feature*num_class,1))</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">ground_truth</span><span class="params">(self,lables)</span>:</span></div><div class="line">        <span class="string">"""将标签转换成ground truth矩阵</span></div><div class="line">        Args:</div><div class="line">            lables:ndarray类型(num_sample*1);表示mnist每张图像对应的标签</div><div class="line">        Returns:</div><div class="line">            dataset:ndarray类型,(num_sample*1０);矩阵的行代表每一个样本，列表示从０～９，矩阵的值位１表示该样本的值是１对应的列数</div><div class="line">        """</div><div class="line">        <span class="comment"># 准备构造数据</span></div><div class="line">        num_sample=lables.shape[<span class="number">0</span>]</div><div class="line">        col=lables.flatten()</div><div class="line">        row=np.arange(num_sample)</div><div class="line">        data=np.ones(num_sample)</div><div class="line">        <span class="comment"># 利用库构造矩阵</span></div><div class="line">        ground_truth=scipy.sparse.csr_matrix((data,(row,col)))</div><div class="line">        <span class="comment"># 转换成稀疏矩阵,同时转成ndarray</span></div><div class="line">        ground_truth=np.array(ground_truth.todense())</div><div class="line">        <span class="keyword">return</span> ground_truth</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">softmax_h</span><span class="params">(self,theta,input)</span>:</span></div><div class="line">        <span class="string">"""获得假设函数h</span></div><div class="line">        Args:</div><div class="line">            theta:ndarray类型,(num_feature*10);表示theta</div><div class="line">            input:ndarray类型，(num_sample*num_feature);表示输入数据</div><div class="line">        Returns:</div><div class="line">            ｈ:ndarray类型,(num_sample*1０);矩阵的每行对应的是该样本是０～９(就是第几列)的概率分别是多少</div><div class="line">        """</div><div class="line">        num_sample=input.shape[<span class="number">0</span>]</div><div class="line">        m=np.dot(input,theta)</div><div class="line">        <span class="comment"># 防止数据overflow,对ｍ进行预处理，已证明对假设函数无影响</span></div><div class="line">        m-=np.max(m,<span class="number">1</span>).reshape(num_sample,<span class="number">1</span>)</div><div class="line">        e=np.exp(m)</div><div class="line">        <span class="comment"># 假设函数h</span></div><div class="line">        h=e/np.sum(e,<span class="number">1</span>).reshape(num_sample,<span class="number">1</span>)</div><div class="line">        <span class="keyword">return</span> h</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">softmax_cost</span><span class="params">(self,theta,input,lables)</span>:</span></div><div class="line">        <span class="string">"""构建损失函数</span></div><div class="line">        Args:</div><div class="line">            theta:ndarray类型,(num_feature*10);表示theta</div><div class="line">            input:ndarray类型，(num_sample*num_feature);表示输入数据</div><div class="line">            lables:ndarray类型(num_sample*1);表示mnist每张图像对应的标签</div><div class="line">        Returns:</div><div class="line">            cost:float类型;表示总的损失</div><div class="line">            theta:ndarray类型,(num_feature*10);表示更新后的theta</div><div class="line">        """</div><div class="line">        num_sample=lables.shape[<span class="number">0</span>]</div><div class="line">        <span class="comment"># 获得样本对应每一个分类的标注信息矩阵(样本是该分类就为１，不是该类则为０)</span></div><div class="line">        ground_truth=self.ground_truth(lables)</div><div class="line">        <span class="comment">#这个地方值得注意，优化器是将上一次得到的theta传进来，第一次是传初始化的theta</span></div><div class="line">        theta=theta.reshape(self.num_feature,self.num_class)</div><div class="line">        h=self.softmax_h(theta,input)</div><div class="line"></div><div class="line"></div><div class="line">        <span class="comment"># 损失函数</span></div><div class="line">        cost=-(np.sum(ground_truth*np.log(h)))/num_sample+<span class="number">0.5</span>*self.lamda*np.sum(theta**<span class="number">2</span>)</div><div class="line">        <span class="comment"># 梯度</span></div><div class="line"></div><div class="line">        grad_theta=-np.dot(input.T,ground_truth-h)/num_sample+self.lamda*theta</div><div class="line"></div><div class="line">        <span class="comment"># 为了满足优化器的要求，将其展开</span></div><div class="line">        grad_theta=grad_theta.flatten()</div><div class="line">        <span class="comment"># print cost</span></div><div class="line">        <span class="keyword">return</span> [cost,grad_theta]</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">softmax_test</span><span class="params">(self,theta,input,lables)</span>:</span></div><div class="line">        <span class="string">"""构建损失函数</span></div><div class="line">        Args:</div><div class="line">            theta:ndarray类型,(num_feature*10);表示theta</div><div class="line">            input:ndarray类型，(num_sample*num_feature);表示输入数据</div><div class="line">            lables:ndarray类型(num_sample*1);表示mnist每张图像对应的标签</div><div class="line">        Returns:</div><div class="line">            accuracy:float类型;表示在测试数据上，学到的模型的正确率</div><div class="line">        """</div><div class="line">        num_sample=lables.shape[<span class="number">0</span>]</div><div class="line">        h=self.softmax_h(theta,input)</div><div class="line">        <span class="comment"># 这个函数有点意思，表示获得ndarray数组每行第一个最大元素所在列的位置</span></div><div class="line">        <span class="comment"># 在这里也就是我们每个测试样本对应的预测值</span></div><div class="line">        res=np.argmax(h,axis=<span class="number">1</span>).reshape(num_sample,<span class="number">1</span>)</div><div class="line"></div><div class="line">        accuracy=np.sum(res==lables)/float(num_sample)</div><div class="line">        <span class="keyword">return</span> accuracy</div><div class="line"></div><div class="line"><span class="comment">########################################</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_mnist_image</span><span class="params">(filename)</span>:</span></div><div class="line">    <span class="string">"""获取mnist图像的特征信息</span></div><div class="line">    Args:</div><div class="line">        filename:str类型;表示mnist图像数据的文件名</div><div class="line">    Returns:</div><div class="line">        dataset:ndarray类型,(num_images*784);矩阵的每一行代表一个图像信息</div><div class="line">    """</div><div class="line">    <span class="comment"># 读二进制文件</span></div><div class="line">    image_file = open(filename, <span class="string">'rb'</span>)</div><div class="line">    buf=image_file.read()</div><div class="line">    image_file.close()</div><div class="line">    <span class="comment"># 读取前4个 32 bit integer,因为它们是数据的描述信息</span></div><div class="line">    index = <span class="number">0</span></div><div class="line">    magic, num_images , num_rows , num_cols = struct.unpack_from(<span class="string">'&gt;IIII'</span> , buf , index)</div><div class="line">    <span class="comment"># 获取图像的特征点个数</span></div><div class="line">    num_feature=num_rows*num_cols</div><div class="line">    index += struct.calcsize(<span class="string">'&gt;IIII'</span>)</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment"># 初始化存储数据的矩阵</span></div><div class="line">    dataset=np.zeros((num_images,num_feature))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,num_images):</div><div class="line">        <span class="comment"># 读入一张图片的数据,28*28</span></div><div class="line">        im = struct.unpack_from(<span class="string">'&gt;784B'</span> ,buf, index)</div><div class="line">        index += struct.calcsize(<span class="string">'&gt;784B'</span>)</div><div class="line">        im=np.array(im)</div><div class="line">        <span class="comment"># 填充数据</span></div><div class="line">        dataset[i,:]=im</div><div class="line"></div><div class="line">    <span class="comment"># 数据归一化</span></div><div class="line">    dataset=dataset/<span class="number">255</span></div><div class="line">    <span class="keyword">return</span> dataset</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_mnist_labels</span><span class="params">(filename)</span>:</span></div><div class="line">    <span class="string">"""获取mnist图像标签的数据</span></div><div class="line">    Args:</div><div class="line">        filename:str类型;表示mnist图像标签的文件名</div><div class="line">    Returns:</div><div class="line">        dataset:ndarray类型,(num_images*1);矩阵的每一行代表一个图像表示的数值</div><div class="line">    """</div><div class="line">    <span class="comment"># 读二进制文件</span></div><div class="line">    image_file = open(filename, <span class="string">'rb'</span>)</div><div class="line">    buf=image_file.read()</div><div class="line">    image_file.close()</div><div class="line">    <span class="comment"># 读取前4个 32 bit integer,因为它们是数据的描述信息</span></div><div class="line">    index = <span class="number">0</span></div><div class="line">    magic, num_labels = struct.unpack_from(<span class="string">'&gt;II'</span> , buf , index)</div><div class="line">    <span class="comment"># 获取图像的特征点个数</span></div><div class="line"></div><div class="line">    index += struct.calcsize(<span class="string">'&gt;II'</span>)</div><div class="line">    <span class="comment"># &gt;60000B 代表按大端取60000个byte数据</span></div><div class="line">    lens=<span class="string">'&gt;'</span>+str(num_labels)+<span class="string">'B'</span></div><div class="line">    labels=struct.unpack_from(lens ,buf, index)</div><div class="line">    labels=np.array(labels).reshape(num_labels,<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> labels</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 初始化各种参数</span></div><div class="line">num_feature=<span class="number">784</span></div><div class="line">num_class=<span class="number">10</span></div><div class="line">lamda=<span class="number">1e-4</span></div><div class="line">max_iterations = <span class="number">100</span></div><div class="line"></div><div class="line"><span class="comment">#########################################</span></div><div class="line"><span class="comment"># 训练</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 加载训练数据</span></div><div class="line">train_images   = load_mnist_image(<span class="string">'./data/train-images.idx3-ubyte'</span>)</div><div class="line">train_labels = load_mnist_labels(<span class="string">'./data/train-labels.idx1-ubyte'</span>)</div><div class="line"></div><div class="line"><span class="comment"># 初始化softmax模型</span></div><div class="line">softmax_model=SoftMax(num_feature,num_class,lamda)</div><div class="line"></div><div class="line"><span class="comment"># 利用优化器迭代数据</span></div><div class="line">opt_solution  = scipy.optimize.minimize(softmax_model.softmax_cost, softmax_model.theta,</div><div class="line">                                            args = (train_images, train_labels), method = <span class="string">'L-BFGS-B'</span>,</div><div class="line">                                            jac = <span class="keyword">True</span>, options = &#123;<span class="string">'maxiter'</span>: max_iterations&#125;)</div><div class="line"></div><div class="line"><span class="comment"># 得到优化后的theta</span></div><div class="line">opt_theta = opt_solution.x.reshape(num_feature,num_class)</div><div class="line"></div><div class="line"><span class="comment">###########################################</span></div><div class="line"><span class="comment"># 测试</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 加载测试数据</span></div><div class="line">test_images   = load_mnist_image(<span class="string">'./data/t10k-images.idx3-ubyte'</span>)</div><div class="line">test_labels = load_mnist_labels(<span class="string">'./data/t10k-labels.idx1-ubyte'</span>)</div><div class="line"></div><div class="line">accuracy=softmax_model.softmax_test(opt_theta,test_images,test_labels)</div><div class="line"></div><div class="line"><span class="keyword">print</span> accuracy</div></pre></td></tr></table></figure>




      
    </div>

    
      
      



      
      
    

    
      <footer class="post-footer">
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2016/07/28/2016-07-28-pla-ml/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">感知学习算法</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2016/08/05/2016-08-05-upload-git/">
        <span class="next-text nav-default">向Github上传项目</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2016/08/02/2016-08-02-softmax-ml/"
           data-title="softmax分类器" data-url="http://yoursite.com/2016/08/02/2016-08-02-softmax-ml/">
      </div>
    
  </div>


        </div>  
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:algoreek@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/tveek" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
        
          <a href="https://www.zhihu.com/people/tveek/activities" class="iconfont icon-zhihu" title="zhihu"></a>
        
      
    
      
    
    
    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>


<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a>
  </span>
  
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2015 - 
    
    2017

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Tveek</span>
  </span>
</div>
      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"tanpan123"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>


  
  




    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  


    <script type="text/javascript" src="/js/src/even.js?v=2.3.x"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=2.3.x"></script>

    
    1<!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


  </body>
</html>
